{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AncoraTamborrino_Project_ComputerVision.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samueleancora/CV2022-AncoraTamborrino/blob/master/AncoraTamborrino_Project_ComputerVision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Computer Vision Project by Ancora Samuele and Tamborrino Michele**\n",
        "\n",
        "The project aims to develop a Neural Network to classify several number of species of fishes, giving also additional pieces of information such as the depth in which they live.\n"
      ],
      "metadata": {
        "id": "lCHxjFEh08QR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import os.path\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import zipfile\n",
        "import os"
      ],
      "metadata": {
        "id": "6KlXGwMk1nOt"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount the drive to obtain the dataset."
      ],
      "metadata": {
        "id": "DNxph0tC8cLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/mydrive')"
      ],
      "metadata": {
        "id": "0fvhVg858an2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5636405b-fdee-49f2-d4dc-4203da1ccbab"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/mydrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_ref = zipfile.ZipFile('mydrive/MyDrive/archive.zip', 'r') #Opens the zip file in read mode\n",
        "zip_ref.extractall('/tmp') #Extracts the files into the /tmp folder\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "T6vk65wV88uJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to handle strings with ease."
      ],
      "metadata": {
        "id": "drF_2sDN9zzZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def join_tuple_string(strings_tuple) -> str:\n",
        "    return ' '.join(strings_tuple)"
      ],
      "metadata": {
        "id": "7NJnJqd29gO4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally we can start."
      ],
      "metadata": {
        "id": "adOxf-0Z96nb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **General settings**"
      ],
      "metadata": {
        "id": "XV-DYLLf4sLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Selected one of the three directory in order to single taking each species\n",
        "image_dir = Path('/tmp/Fish_Data/images/cropped')\n",
        "print(\"Image dir:\" + str(image_dir))\n",
        "\n",
        "# Take all the objects that have anything in the name and ends with .png\n",
        "filepaths = list(image_dir.glob(r'**/*.png'))\n",
        "\n",
        "# Uses join_tuple_string that takes as argument the list of the tuples containing the species's name\n",
        "labels = list(map(join_tuple_string, list(map(lambda x: os.path.split(x)[1].split(\"_\", 2)[:2], filepaths))))\n",
        "print(\"I found \" + str(len(labels)) + \" elements.\")\n",
        "\n",
        "# Creates a sort of column in a table\n",
        "filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
        "labels = pd.Series(labels, name='Label')\n",
        "\n",
        "# Concatenates previous columns providing a data frame.\n",
        "image_df = pd.concat([filepaths, labels], axis=1)\n",
        "\n",
        "###############################################################################################\n",
        "# This may be useful in order to take out from the labeling the images with unwanted names.   #\n",
        "# Since we have a small number (~40) images called like CUNWCB, we may think to drop them.    #\n",
        "image_df['Label'] = image_df['Label'].apply(lambda x: np.NaN if x[-3:] == 'png' else x)  #\n",
        "image_df = image_df.dropna(axis=0)  #\n",
        "# print(image_df)                                                                             #\n",
        "###############################################################################################\n",
        "\n",
        "samples = []\n",
        "\n",
        "for category in image_df['Label'].unique():\n",
        "    category_slice = image_df.query(\"Label == @category\")\n",
        "    samples.append(category_slice.sample(20, random_state=1, replace=True))\n",
        "\n",
        "image_df = pd.concat(samples, axis=0).sample(frac=1.0, random_state=1).reset_index(drop=True)\n",
        "print(image_df)\n",
        "\n",
        "# We may look at the numbers for each species\n",
        "print(image_df['Label'].value_counts())\n",
        "\n",
        "# Create the train and test set\n",
        "train_df, test_df = train_test_split(image_df, train_size=0.6, shuffle=True, random_state=3)\n",
        "\n",
        "# This process helps us to not run out of memory, loading an image per time\n",
        "# This is responsible for image augmentation\n",
        "train_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "test_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n",
        ")\n",
        "\n",
        "train_images = train_generator.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Label',\n",
        "    target_size=(224, 224),\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=42,\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_images = train_generator.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Label',\n",
        "    target_size=(224, 224),\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=True,\n",
        "    seed=42,\n",
        "    subset='validation'\n",
        ")\n",
        "\n",
        "test_images = test_generator.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    x_col='Filepath',\n",
        "    y_col='Label',\n",
        "    target_size=(224, 224),\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=32,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "print(test_images)\n",
        "\n",
        "# We will use a pre trained model, which is MobileNetV2 transfer CNN model.\n",
        "pretrained_model = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3),\n",
        "                                                     include_top=False,\n",
        "                                                     weights='imagenet',\n",
        "                                                     pooling='avg'\n",
        "                                                     )\n",
        "#\n",
        "pretrained_model.trainable = False\n",
        "\n",
        "# By doing this we are able to take the first input layer\n",
        "inputs = pretrained_model.input\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(pretrained_model.output)\n",
        "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
        "\n",
        "outputs = tf.keras.layers.Dense(479, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)"
      ],
      "metadata": {
        "id": "NiXZV31I952-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model compile and fit**"
      ],
      "metadata": {
        "id": "WLxyox7B3_Ea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_images,\n",
        "    validation_data=val_images,\n",
        "    epochs=8,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=3,\n",
        "            restore_best_weights=True\n",
        "        )\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "7oGx8HHf4BAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Plotting metrics**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ga2qGoAK3t2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.savefig('mydrive/MyDrive/plots/model_accuracy.png')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.savefig('mydrive/MyDrive/plots/model_loss.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j6Z6SVr83yYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Model evaluation**"
      ],
      "metadata": {
        "id": "CZScm2FY3gdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.evaluate(test_images, verbose=0)\n",
        "print(\"    Test loss: {:.5f}\".format(result[0]))\n",
        "print(\"Test accuracy: {:.2f}%\".format(result[1] * 100))"
      ],
      "metadata": {
        "id": "woL-zat43oe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Predict species**"
      ],
      "metadata": {
        "id": "BdEjTWJ82eqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_images.reset()\n",
        "pred = model.predict(test_images, verbose=0)\n",
        "\n",
        "predicted_class_indices = np.argmax(pred, axis=1)\n",
        "\n",
        "labels = train_images.class_indices\n",
        "labels = dict((v, k) for k, v in labels.items())\n",
        "predictions = [labels[k] for k in predicted_class_indices]\n",
        "print(\"I found \" + str(len(labels)) + \" labels.\")\n",
        "print(\"I found \" + str(len(predictions)) + \" predictions.\")"
      ],
      "metadata": {
        "id": "plnLZ0jnrXpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Save results into a .csv file**"
      ],
      "metadata": {
        "id": "W3kIdvXu2RwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filenames = test_images.filenames\n",
        "results = pd.DataFrame({\"Filename\": filenames,\n",
        "                        \"Predictions\": predictions})\n",
        "results.to_csv(\"results.csv\", index=False)"
      ],
      "metadata": {
        "id": "Xo87wcVUqqVM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}